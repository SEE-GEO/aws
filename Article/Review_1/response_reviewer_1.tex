\documentclass[11pt,a4paper,draft]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{natbib}
%\usepackage{showframe} %This line can be used to clearly show the new margins

\newgeometry{vmargin={30mm}, hmargin={25mm,25mm}} 
\setlength{\topskip}{0mm}

\begin{document}
	\title{\textbf{Response to Reviewer 1}}
	\date{}
	\maketitle


The authors would like to thank the reviewer for his/her careful review and constructive comments, which we believe will help improve the content of the manuscript.  Below, under each bullet point, we provide a point by point response to each comment/question. The author responses are given in blue, and textual changes are italicised.  

\section*{General comments}

\begin{itemize}

\item 	``precipitation and most dense clouds'' I think the hydrometeor size is an important.\\
		
		
\textcolor{blue}{Reply: We agree that the hydrometeor size is an important aspect, but when it comes to an overview of the cloud contamination at 183\,GHz, precipitating clouds and clouds with large optical thickness have the strongest effect, and a dense cloud could be composed of hydrometeors of different shapes and sizes. }\\
		
		
\item	L66: ``only using measurements (no background data involved)'' My understanding is
		that the method is in theory model-free, but for the demonstration in this study, simulations (e.g. background simulated at MWHS2 frequency) are used. Am I correct?
		Maybe this should be stressed here. Why not try with real MWHS2 observation for the
		all sky dataset?\\
		
\textcolor{blue}{Reply: Yes, the demonstration of the entire concept is based on simulations. We do not try with the real MWHS-2 observations as the validation of the training process could only be performed against clear-sy simulations. To stress on the fact that only background MWHS-2 observations are used, we have added the following text to Sect. 2.1.1:\\
Pg 4, line 104:
``\textit{For the demonstation of the study, MWHS-2 background or simulations are used. Actual measurements are not taken into account. The requisite data was obtained from ECMWF. More details are described in Sect.2.1.1}.''} \\
		
		
\item
		L137 "Simulations for all three sensors are noise free, so to incorporate the measurement uncertainties, whenever needed, Gaussian noise is added according to the channel NEDT (Table 1 - Table 3)." Are the errors arising from the radiative transfer calculation accounted for?\\
		
\textcolor{blue}{Reply: The most important errors arising from radiative transfer calculations, are related to representing the cloud microphysics. In this study, for ICI and SMS, we consider only one particle size distribution (PSD) and habit and this could underestimate the true cloud variability. Underestimation of scattering at higher frequencies can lead to some imperfections in mapping the cloud information from sub-mm and 183\,GHz. Other factors affecting the accuracy of simulations, but not considered due to brevity include neglected antenna pattern and limitations associated with input data, both Cloudsat and ERAInterim. For example, the simulations could have tendency to be biased towards the Cloudsat geographical sampling. The actual background departures and the corresponding bias correction shall only be revealed when data from ICI is available in future.\\
We have added a short description these radiative transfer errors that could affect the simulations in Sect. 2.2.  } \\
		
	
		
\item	
		L159: "for all selected quantile fractions " by quantile fraction, do you mean the n th
		amongst the 7 selected (from 0.2 to 99.8\%)? Also, 16, 50 and 85\% are not symmetric
		(rounding?)\\
		
\textcolor{blue}{Reply: Yes, the selected quantiles are the seven percentiles mentioned. We re-phrase some sentences here to make it more clear. 85\% is a typo, it should be 84\%. It has been corrected.}\\
		
		
\item	
		L163: Pfreundschuh uses an indicator function I (=1 or 0) in the CRPS, the authors
		here use y, can they explain the difference?\\
		
\textcolor{blue}{Reply: In the study by \citet{pfreundschuh:aneur:18}, CRPS is defined as using an indicator function ($I$), however for QRNN the integral is evaluated only by approximation. To calculate the CRPS, we use a piece-wise linear fit to the approximate posterior CDF obtain from the predicted quantiles. This approximation is further used to calculate CRPS.}\\
		
		
\item	
		L173: " The input data is all-sky brightness temperature" the simulated one, even for
		MWHS2, right? \\
		
\textcolor{blue}{Reply: Yes, even for MWHS-2 we use simulated all-sky brightness temperatures.}\\
		
		
\item	L301: "0.15 K" should be -0.15 \\
		
\textcolor{blue}{Reply: The correction is made.} \\
		
		
	
\item	
		L453: "Among these four channels, 150 GHz has the highest peaking function around 4
		C2km (Chen and Bennartz, 2020)" Could you please clarify what you mean here, 150GHz
		is neither the highest nor the lowest peaking channel nor it peaks at 4km. Channel 89,
		118+/-1.1, 118+/-2.5, and 150 GHz peak at 0.1, 9.6, 2.9, 1km, respectively (according
		to Chen and Bennartz, 2020), this can also be seen in Lawrence et al. (2018) Fig. 1
		through the Jacobians of channels 6 and 7.\\
	
\textcolor{blue}{Reply: The reviewer is correct. It was wrongly mentioned that 150 GHz is the highest peaking channel, at 4\,km. We have corrected the text and it now reads as:	\\
Pg 25, line 465:	
``\textit{The channels, 150\,GHz and 118.75$\pm$2.5 peak between surface and 4\,km. These channels can only provide coverage to the humidity channels in the lower and mid troposphere. However, the 183\,GHz channels are sensitive to hydrometeor content up to 10\,km. The channel 118.75$\pm$1.1 peaks around 10\,km, but such information is only partly relevant for the higher peaking channels of 183\,GHz.}'' }\\

		
\item	L460: "but such information would be not be completely orthogonal" duplicate "be"
		
\textcolor{blue}{Reply: The duplicate word is removed. }\\
		
		
		
\item	
		Table 1: NEDT are constructor specifications, the real noise is lower, see
		Fig 5 Guo, Y., J. Y. He, S. Y. Gu, and N. M. Lu, 2019: Calibration and validation of
		Feng Yun-3-D microwave humidity sounder II. \\
		IEEE Geoscience and Remote Sensing
		Letters, doi:10.1109/LGRS.2019.2957403.
		Tab 5 Carminati, F., Atkinson, N., Candy, B., Lu, Q.: Insights into the Microwave Instruments Onboard the Feng-Yun 3D Satellite: Data Quality and Assimilation in the Met Office NWP System. Adv. Atmos. Sci. (2020). https://doi.org/10.1007/s00376-020-0010-1 \\
	
\textcolor{blue}{Reply: The reviewer rightly mentions that the real noise is lower, however we add the sensor noise according to the constructor specifications. This can be viewed as a conservative estimate of the sensor noise to include other sources of error not accounted for in NEDT. For example in study \citet{Carminati-fy3d-2020} the authors describe radiation leak affecting the higher frequency channels.}

\end{itemize}

		
		
\section*{Questions}
\begin{itemize}
		
\item	
		Is this method applicable to IR e.g. to an ATOVS system?\\
	
\textcolor{blue}{Reply:  Yes, the method could potentially be applied to IR. The operation and  performance of the cloud correction approach is based on the fact that different frequencies have varying sensitivity to cloud signatures in the same field of view. For IR, infact this feature is regularly used to flag out cloud contamination. Most cloud flagging schemes for IR are based on brightness temperature thresholds.
}\\

\item 		
		The authors explain that it could benefit the all-sky assimilation systems indirectly for
		the analysis increment. Instead (or in addition) could it be used to model the variable
		observation error (when and by how much to be inflated)? This would be, in my view,
		the most valuable.	\\
			
\textcolor{blue}{Reply: The reviewer has a very good point. At ECMWF, the observational errors for MHS and MWHS-2 are defined as quadratic functions of symmetric cloud indicator \citep{geer2015scatteringindex}. The observational errors are higher in regions for cloud and vice-versa. Thus it could be potentially feasible to use the QRNN identified cloud impact to formulate the observational errors.  This could probably be the best use of the QRNN technique for all-sky. Of course using QRNN to develop a full observational model, would require to characterize the performance of the scheme over upper latitudes, land and ocean.}\\
		
\item	Could the uncertainty use for weak constraint 4dvar?\\
		
\textcolor{blue}{Reply: Although, the uncertainties obtained from QRNN do not have a direct application to weak constraint 4dvar, but they could still be considered as a diagnostic to help evaluate the weak constraint in the troposphere. For example, undiagnosed cirrus contamination in the upper troposphere might be associated with apparent model biases that are actually caused by systematic forward model errors. }\\
		
		
		
\item	
		What is the resource cost of this method (is this fast enough to be used in 1-h regional
		nwp with 30min window)?\\
	
\textcolor{blue}{Reply:  Yes, it would be feasible to implement the scheme into existing NWP models. In this study, QRNN was not optimized to get the maximum computational performance. For each MWHS-2 channel, it took around 30 minutes to train the net on a  x86\_64, 8 CPU machine. However, with the modern computing architectures and parallel processing, a much faster computation can be expected. }\\
		
\end{itemize}
		
 \bibliographystyle{copernicus}
 \bibliography{references}	
	
\end{document}