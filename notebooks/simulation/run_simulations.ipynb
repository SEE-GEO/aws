{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running simulations\n",
    "\n",
    "The basic functionality for performing the AWS simulations is implemented by the `aws` package. With this in place, running simulations is a matter of setting up the simulations with the desired parameters and then executing them via IPyParallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipyparallel as ipp\n",
    "import os\n",
    "from aws.retrieval import Simulation, Retrieval\n",
    "from aws.data import RandomProfile\n",
    "from aws.sensor import ATMS, AWS\n",
    "from aws import aws_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to IPyParallel\n",
    "\n",
    "Assuming that the IPyParallel controller, hub and engines are running we create a client, which holds the connection to the controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws.retrieval import Retrieval\n",
    "client = ipp.Client(profile=\"gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are already running 4 engines on each of the gold machines, which only have 4 cores, we set the `OMP_NUM_THREADS` environment variable to 1 on all engines to avoid ARTS from launching to many threads.\n",
    "\n",
    "Note that this notebook is running on your local machine, not on the gold cluster. To execute a cell on the engines we need to use\n",
    "the  `%%px` cell magic, which executes the cell on the remote engines instead on the local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] env: OMP_NUM_THREADS=1\n",
      "[stdout:1] env: OMP_NUM_THREADS=1\n",
      "[stdout:2] env: OMP_NUM_THREADS=1\n",
      "[stdout:3] env: OMP_NUM_THREADS=1\n",
      "[stdout:4] env: OMP_NUM_THREADS=1\n",
      "[stdout:5] env: OMP_NUM_THREADS=1\n",
      "[stdout:6] env: OMP_NUM_THREADS=1\n",
      "[stdout:7] env: OMP_NUM_THREADS=1\n",
      "[stdout:8] env: OMP_NUM_THREADS=1\n",
      "[stdout:9] env: OMP_NUM_THREADS=1\n",
      "[stdout:10] env: OMP_NUM_THREADS=1\n",
      "[stdout:11] env: OMP_NUM_THREADS=1\n",
      "[stdout:12] env: OMP_NUM_THREADS=1\n",
      "[stdout:13] env: OMP_NUM_THREADS=1\n",
      "[stdout:14] env: OMP_NUM_THREADS=1\n",
      "[stdout:15] env: OMP_NUM_THREADS=1\n",
      "[stdout:16] env: OMP_NUM_THREADS=1\n",
      "[stdout:17] env: OMP_NUM_THREADS=1\n",
      "[stdout:18] env: OMP_NUM_THREADS=1\n",
      "[stdout:19] env: OMP_NUM_THREADS=1\n",
      "[stdout:20] env: OMP_NUM_THREADS=1\n",
      "[stdout:21] env: OMP_NUM_THREADS=1\n",
      "[stdout:22] env: OMP_NUM_THREADS=1\n",
      "[stdout:23] env: OMP_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "%env OMP_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the simulation\n",
    "\n",
    "The next step is to setup the simulation with the desired configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the sensor\n",
    "\n",
    "Currently two sensor configurations are available:\n",
    "\n",
    "  * `ATMS`: Simplified version of the upper channels of the\n",
    "     ATMS sensor.\n",
    "  * `AWS`: The channel setup to use for the full simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = ATMS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the ice habit\n",
    "\n",
    "The ice shape to use in the simulations. Shoule be one of\n",
    "* `\"Perpendicular3BulletRosette\"`\n",
    "* `\"LargePlateAggregate\"`\n",
    "* `\"LargeColumnAggregate\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_shape = \"Perpendicular3BulletRosette\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the simulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data.\n",
    "data_provider = RandomProfile(\"~/Dendrite/Projects/AWS-325GHz/CasesV1\")\n",
    "\n",
    "# Setup the IWC/RWC retrieval, which then becomes the\n",
    "# data_provider for the simulation.\n",
    "retrieval = Retrieval(data_provider, ice_shape)\n",
    "\n",
    "# Setup the simulation\n",
    "simulation = Simulation(sensor, retrieval, ice_shape)\n",
    "inputs = [(\"filename\", (\"name_length\",)),\n",
    "          (\"profile_index\", ())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(aws_path, \"data\", \"simulations_allsky_v1.nc\")\n",
    "simulation.initialize_output_file(filename,\n",
    "                                 [(\"cases\", -1, 0)], # Name of dimension for different simulations\n",
    "                                 inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the simulations\n",
    "\n",
    "Running the simulations is performed by executing the `run_ranges` method which distributes the simulations for the given range of profiles on the IPyParallel cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/simonpf/src/artssat/artssat/simulation.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "   403    296.0 MiB    296.0 MiB       @profile\n",
      "   404                                 def run_ranges(self,\n",
      "   405                                                *args,\n",
      "   406                                                mpi = None,\n",
      "   407                                                ipyparallel_client = None,\n",
      "   408                                                callback = None,\n",
      "   409                                                **kwargs):\n",
      "   410                             \n",
      "   411    296.0 MiB      0.0 MiB           if mpi is None:\n",
      "   412    296.0 MiB      0.0 MiB               parallel = self.parallel\n",
      "   413                                     else:\n",
      "   414                                         if not ipyparallel_client is None:\n",
      "   415                                             raise ValueError(\"Simulations can be run either using MPI or \"\n",
      "   416                                                              \" IPyParallel, not both. Therefore, only \"\n",
      "   417                                                              \"one of the mpi and ipyparallel_client keyword \"\n",
      "   418                                                              \"arguments can be given.\")\n",
      "   419                                         parallel = mpi\n",
      "   420                             \n",
      "   421    296.0 MiB      0.0 MiB           ranges = list(args)\n",
      "   422                             \n",
      "   423    296.0 MiB      0.0 MiB           if parallel:\n",
      "   424                                         self._run_ranges_mpi(ranges, **kwargs, callback = callback)\n",
      "   425    296.0 MiB      0.0 MiB           elif ipyparallel_client:\n",
      "   426    296.0 MiB      0.0 MiB               return self._run_ranges_ipyparallel(ranges,\n",
      "   427    296.0 MiB      0.0 MiB                                                   **kwargs,\n",
      "   428    296.0 MiB      0.0 MiB                                                   callback = callback,\n",
      "   429    794.4 MiB    498.4 MiB                                                   ipyparallel_client=ipyparallel_client)\n",
      "   430                                     else:\n",
      "   431                                         self._run_ranges(ranges, **kwargs, callback = callback)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = simulation.run_ranges(range(20000, 30000), ipyparallel_client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distributed ARTS simulation: 10000 tasks, 10000 completed, 0 failed\n",
       "\t Avg. execution time: 0:01:05.379839"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulations are executed asynchronously, which means the `run_ranges` will return berfore the simulations are finished. To monitor progress you can print the results object, which will display the amount of completed simulations. If any simulations failed, the exceptions can be accessed via the `results.failed` attribute.\n",
    "\n",
    "> **NOTE:** The profile order is random but fixed. Running `simulation.run_ranges(1000)` multiple times will produce the same\n",
    " results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running clearsky simulations\n",
    "\n",
    "Running clearsky simulations is performed in a separate simulation. All that is required to run clearsky versions of the simulations is to pass the `clearsky=True` keyword argument to the `run_ranges` method.\n",
    "\n",
    "Note, however, that you will need to write the results to a different file, otherwise the results from the allsky simulations will be overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "filename = os.path.join(aws_path, \"data\", \"simulations_clearsky_v1.nc\")\n",
    "simulation.initialize_output_file(filename,\n",
    "                                 [(\"cases\", -1, 0)], # Name of dimension for different simulations\n",
    "                                 inputs=inputs)\n",
    "results = simulation.run_ranges(range(n),\n",
    "                                ipyparallel_client=client,\n",
    "                               clearsky=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distributed ARTS simulation: 10000 tasks, 9999 completed, 1 failed\n",
       "\t Avg. execution time: 0:00:04.527508"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
